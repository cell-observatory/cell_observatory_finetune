_target_: cell_observatory_finetune.models.meta_arch.maskedautoencoder.FinetuneMaskedAutoEncoder
input_fmt: ${dataset_layout_order}
input_shape: ${datasets.input_shape}
patch_shape: ${datasets.patch_shape}

embed_dim: 4096
# decoder_embed_dim: 512
depth: 32
# decoder_depth: 8
num_heads: 32
# decoder_num_heads: 8
mlp_ratio: 4.0

proj_drop_rate: 0.0
att_drop_rate: 0.0
drop_path_rate: 0.1
init_std: 0.02
fixed_dropout_depth: false
# use_conv_proj: false
norm_layer: RmsNorm
act_layer: SiLU
mlp_layer: SwiGLU

# mask_ratio: 0.75
# window_mask_shape: null

abs_sincos_enc: true
rope_pos_enc: false
rope_random_rotation_per_head: true
rope_mixed: false
rope_theta: 100.0
weight_init_type: mae
mlp_wide_silu: false
loss_fn: l2_masked