defaults:
  - databases: supabase_database      # Loads configs/datasets/databases/supabase_database.yaml
  - transforms: ray_transforms        # Loads configs/datasets/transforms/ray_transforms.yaml
  - _self_

# mainly used by other configs but determined here for ease of access
batch_size: ${clusters.batch_size_per_gpu} # batch size = (total_batch_size * total_gpus)
input_shape: [16, 128, 128, 128, 2] 
patch_shape: [4, 16, 16, 16]

max_rois: null # maximum number of ROIs (each ROI can have dozens of tiles)
max_tiles: null # maximum number of tiles (each tile can have thousands of hypercubes)
max_hypercubes: null # maximum number of hypercubes to return

hpf_list: null # list of specific HPFs (hours-post-fertilization in hours) to filter
roi_list: null # list of specific ROIs to filter
tile_list: null # list of specific tiles to filter

occupancy_threshold: 0.9 # to filter our hypercubes with less than this occupancy ratio (0.0-1.0)

use_cached_hypercubes_dataframe: false # whether to use the cached hypercubes dataframe
hypercubes_dataframe_path: ${paths.outdir}/database/hypercubes_dataframe.csv # path to the hypercubes dataframe (path/to/repo/databases/default_hypercubes_dataframe.csv)
server_folder_path: ${paths.server_folder_path}

split: 0.2
return_dataloader: true
distributed_sampler: true
prefetch_factor: 1 # prefetch factor for the dataloader
num_workers: ${clusters.cpus_per_worker}  # number of workers for the dataloader

drop_last_policy: true # whether to drop the last batch if it is smaller than the batch size

collate_fn:
  _target_: data.datasets.pretrain_dataset_ray.CollatorActor
  dtype: ${dataset_dtype}
  buffer_dtype: ${storage_dtype}
  batch_size: ${clusters.batch_size_per_gpu}
  input_shape: ${datasets.input_shape}
  device_buffer_capacity: 2
  pin_numa_node: ${datasets.pin_numa_node}
  pin_pages: ${datasets.pin_memory}

dataset:
  _target_: data.datasets.pretrain_dataset_ray.PretrainDatasourceRay
  hypercubes_dataframe_path: ${datasets.hypercubes_dataframe_path}
  server_folder_path: ${datasets.server_folder_path}
  max_rois: ${datasets.max_rois}
  max_tiles: ${datasets.max_tiles}
  max_hypercubes: ${datasets.max_hypercubes}
  hpf_list: ${datasets.hpf_list}
  roi_list: ${datasets.roi_list}
  tile_list: ${datasets.tile_list}
  input_layout:
    _target_: data.data_shapes.MULTICHANNEL_HYPERCUBE
    value: ${dataset_layout_order}

use_arrow_tensor_v2: true # use Arrow Tensor v2
locality_with_output: true # whether to use locality with output for the Ray tasks
rows_per_block: ${clusters.batch_size_per_gpu} # ${clusters.batch_size} # number of rows per block for the Ray dataset
buffer_capacity: 24
pin_numa_node: true
pin_memory: true
max_concurrent_calls: 512
numa_node_affinity_policy: "distance"
numa_oversub_factor: 2.0
actor_oversub_factor: 2.0

channels_subset: null # subset of channels to use, e.g. [0, 1] for first two channels
num_actors_min: 12
num_actors_max: 12
with_batched_api: true
context:
  file_io_concurrency: null # concurrency for file I/O operations
  data_copy_concurrency: null # concurrency for data copy operations
  cache_pool: 
    total_bytes_limit: 0

debug: false