defaults:
  - _self_

name: skittlez

batch_size: 12 # 4 # total batch size (batch_size per gpu * number of gpus) 

dataset_mean: [1000.0] # not currently used, placeholder for dataset mean
dataset_std: [1000.0] # not currently used, placeholder for dataset std

# Data Parameters
channel_in: 3
num_classes: 2 
input_shape: 256
inputs:
  - ${datasets.batch_size}
  - ${datasets.channel_in}
  - ${datasets.input_shape}
  - ${datasets.input_shape}
  - ${datasets.input_shape}

database:
  _target_: segmentation.data.datasets.skittlez.Skittlez_Database
  db_path: /clusterfs/nvme/segment_4d/final_pipeline_v3/db/segmentation_curation_test.db
  train_db_savedir: /clusterfs/nvme/segment_4d/test/db
  selection_criteria: {"volume" : 8000}  # Minimum volume in pixels to accept instance
  force_create_db: false
  clean_up_db: false
  with_zarr: false
  with_tiff: true
  metadata: null
  batch_config:
    _target_: segmentation.data.data_utils.DataConfig
    z: 128
    y: 256
    x: 256
    c: 3
    color_mode: MATCH  

transforms:
  - _target_: segmentation.data.transforms.transforms.Normalize
    # mean: ${dataset_mean}
    # std: ${dataset_std}

split: 0.1 
return_dataloader: true 
workers: 1     
collate_fn: segmentation.data.data_utils.collate_fn_segmentation
worker_init_fn: segmentation.data.data_utils.worker_init_fn_db