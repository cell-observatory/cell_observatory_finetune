defaults:
  - models: maskdino # Loads configs/models/maskdino.yaml
  - models/preprocessors: preprocessor # Loads configs/models/preprocessors/preprocessor.yaml
  - models/backbones: resnet # Loads configs/models/backbones/resnet.yaml
  - models/heads: maskdino_head # Loads configs/models/heads/maskdino_head.yaml
  - models/matchers: maskdino_matcher # Loads configs/models/utils/matchers/maskdino_matcher.yaml
  - datasets: instance_segmentation # Loads configs/datasets/instance_segmentation.yaml
  - losses: maskdino # Loads configs/losses/maskdino.yaml
  - transforms: transforms_skittlez # Loads configs/transforms/transforms_skittlez.yaml
  - optimizers: adamw # Loads configs/optimizers/adamw.yaml
  - schedulers: warmup_cosine_decay # Loads configs/schedulers/warmup_cosine_decay.yaml
  - metrics: metrics # Loads configs/metrics/metrics.yaml
  - deepspeed: deepspeed # Loads configs/deepspeed/deepspeed.yaml
  - clusters: local # Loads configs/clusters/slurm_multinode.yaml
  - _self_  # self reference last to allow for overrides

# overrides
# ----------------

# Backbone (TODO: not technically an override, but probably should be) 
backbone_target: segmentation.models.backbones.resnet.resnet50 # options: resnet50, resnet101, resnet152
backbone_out_channels: 512 # C5 = 2048

models:
  backbones:
    return_intermediates: True # return intermediate features from the backbone

clusters:
  batch_size:               1          # NOTE: batch size should divide im2col_step in deformable attn
  total_cpus:               4          # total number of cpus to use
  total_gpus:               1          # total number of gpus to use
  gpus_per_worker:          1          # number of gpus to use per node
  mem_per_worker:           31000      # memory per node
  cpus_per_worker:          4          # number of cpus to use per node  
  workers:                  1          # number of nodes to use 

# ----------------

# Model type
network: maskdino

# Training paradigm
paradigm: segmentation.train.backend_segmentation.supervised

# Paths
outdir: /clusterfs/nvme/segment_4d/test_17
logdir: ${outdir}/logs

load_checkpointdir: null # specify if we want to load a checkpoint from a previous run that is not latest local run
checkpointdir: ${outdir}/checkpoints # specify where to save the checkpoints
checkpoint_update_interval: 100 # save checkpoint every N epochs

val_interval: 1
log_step: 100 # step interval to show training loss in train loop
val_log_step: 20 # step interval to show loss in val loop

train_db_savedir: ${outdir}/db
db_path: /clusterfs/nvme/segment_4d/final_pipeline_v3/db/segmentation_curation_test.db