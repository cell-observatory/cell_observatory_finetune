from typing import Tuple

import torch
from torch import Tensor

from cell_observatory_finetune.models.ops.roi_align_nd import RoIAlign3DFunction


def convert_bbox_format(bboxes, bbox_input_format, bbox_output_format):
    """
    Convert bounding boxes from one format to another.
    Supported formats: 'cxcyczwhd', 'xyzxyz'
    """
    if bbox_input_format == bbox_output_format:
        return bboxes
    if bbox_input_format == 'cxcyczwhd' and bbox_output_format == 'xyzxyz':
        return box_cxcyczwhd_to_xyzxyz(bboxes)
    elif bbox_input_format == 'xyzxyz' and bbox_output_format == 'cxcyczwhd':
        return box_xyzxyz_to_cxcyczwhd(bboxes)
    else:
        raise ValueError(f"Unsupported bbox format conversion from {bbox_input_format} to {bbox_output_format}")


def box_cxcyczwhd_to_xyzxyz(boxes: Tensor) -> Tensor:
    """
    Converts bounding boxes from (cx, cy, cz, w, h, d) format to (x1, y1, z1, x2, y2, z2) format.
    (cx, cy, cz) refers to center of bounding box
    (w, h, d) are width and height of bounding box
    Args:
        boxes (Tensor[N, 6]): boxes in (cx, cy, cz, w, h, d) format which will be converted.

    Returns:
        boxes (Tensor(N, 6)): boxes in (x1, y1, z1, x2, y2, z2) format.
    """
    # We need to change all 6 of them so some temporary variable is needed.
    cx, cy, cz, w, h, d = boxes.unbind(-1)
    x1 = cx - 0.5 * w
    y1 = cy - 0.5 * h
    z1 = cz - 0.5 * d
    x2 = cx + 0.5 * w
    y2 = cy + 0.5 * h
    z2 = cz + 0.5 * d

    boxes = torch.stack((x1, y1, z1, x2, y2, z2), dim=-1)

    return boxes


# Implementation adapted from https://github.com/facebookresearch/detr/blob/master/util/box_ops.py
def generalized_box_iou(boxes1: Tensor, boxes2: Tensor) -> Tensor:
    """
    Return generalized intersection-over-union (Jaccard index) between two sets of boxes.

    Both sets of boxes are expected to be in ``(x1, y1, z1, x2, y2, z2)`` format with
    ``0 <= x1 < x2`` and ``0 <= y1 < y2`` and ``0 <= z1 < z2``.

    Args:
        boxes1 (Tensor[N, 6]): first set of boxes
        boxes2 (Tensor[M, 6]): second set of boxes

    Returns:
        Tensor[N, M]: the NxM matrix containing the pairwise generalized IoU values
        for every element in boxes1 and boxes2
    """
    inter, union = _box_inter_union(boxes1, boxes2)
    iou = inter / union

    lti = torch.min(boxes1[:, None, :3], boxes2[:, :3])
    rbi = torch.max(boxes1[:, None, 3:], boxes2[:, 3:])

    whi = _upcast(rbi - lti).clamp(min=0)  # [N,M,3]
    vol_i = whi[:, :, 0] * whi[:, :, 1] * whi[:, :, 2]

    return iou - (vol_i - union) / vol_i


def project_masks_on_boxes(gt_masks, boxes, matched_idxs, M):
    """
    Given segmentation masks and the bounding boxes corresponding
    to the location of the masks in the image, this function
    crops and resizes the masks in the position defined by the
    boxes. This prepares the masks for them to be fed to the
    loss computation as the targets.
    """
    matched_idxs = matched_idxs.to(boxes)
    rois = torch.cat([matched_idxs[:, None], boxes], dim=1)
    gt_masks = gt_masks[:, None].to(rois)
    
    roi_align = RoIAlign3DFunction.apply

    gt_masks_gpu = gt_masks.to("cuda")
    rois_gpu = rois.to("cuda")

    result = roi_align(gt_masks_gpu, rois_gpu, (M, M, M), 1.0)[:, 0] 
    result = result.to(gt_masks.device)
    return result


def masks_to_boxes(masks: torch.Tensor) -> Tensor:
    """
    Compute the bounding boxes around the provided masks.

    Returns a [N, 6] tensor containing bounding boxes. The boxes are in ``(x1, y1, x2, y2)`` format with
    ``0 <= x1 <= x2`` and ``0 <= y1 <= y2`` and ``0 <= z1 < z2``.

    .. warning::

        In most cases the output will guarantee ``x1 < x2`` and ``y1 < y2`` and ``0 <= z1 < z2``. But
        if the input is degenerate, e.g. if a mask is a single row or a single
        column, then the output may have x1 = x2 or y1 = y2 or z1=z2.

    Args:
        masks (Tensor[N, D, H, W]): masks to transform where N is the number of masks
            and (D, H, W) are the spatial dimensions.

    Returns:
        Tensor[N, 6]: bounding boxes
    """
    if masks.numel() == 0:
        return torch.zeros((0, 6), device=masks.device, dtype=torch.float)

    n = masks.shape[0]

    bounding_boxes = torch.zeros((n, 6), device=masks.device, dtype=torch.float)

    for index, mask in enumerate(masks):
        z, y, x = torch.where(mask != 0)

        bounding_boxes[index, 0] = torch.min(x)
        bounding_boxes[index, 1] = torch.min(y)
        bounding_boxes[index, 2] = torch.min(z)
        bounding_boxes[index, 3] = torch.max(x)
        bounding_boxes[index, 4] = torch.max(y)
        bounding_boxes[index, 5] = torch.max(z)

    return bounding_boxes


# TODO: reconcile masks_to_boxes and masks_to_boxes_v2
def masks_to_boxes_v2(masks, eps: float = 1e-1) -> Tensor:
    """
    Compute the bounding boxes around the provided masks.
    The masks should be in format [N, D, H, W] where N is 
    the number of masks, (D, H, W) are the spatial dimensions.
    Returns a [N, 6] tensors, with the boxes in xyxy format
    """
    if masks.numel() == 0:
        return torch.zeros((0, 6), device=masks.device)

    d, h, w = masks.shape[-3:]

    z = torch.arange(0, d, dtype=torch.float, device=masks.device)
    y = torch.arange(0, h, dtype=torch.float, device=masks.device)
    x = torch.arange(0, w, dtype=torch.float, device=masks.device)
    z, y, x = torch.meshgrid(z, y, x, indexing='ij')

    x_mask = (masks * x.unsqueeze(0))
    x_max = x_mask.flatten(1).max(-1)[0]
    x_min = x_mask.masked_fill(~(masks.bool()), 1e8).flatten(1).min(-1)[0]

    y_mask = (masks * y.unsqueeze(0))
    y_max = y_mask.flatten(1).max(-1)[0]
    y_min = y_mask.masked_fill(~(masks.bool()), 1e8).flatten(1).min(-1)[0]

    z_mask = (masks * z.unsqueeze(0))
    z_max = z_mask.flatten(1).max(-1)[0]
    z_min = z_mask.masked_fill(~(masks.bool()), 1e8).flatten(1).min(-1)[0]

    mask = torch.stack([x_min, y_min, z_min, x_max, y_max, z_max], 1).to(masks.device, torch.float)
    invalid_mask = (torch.isinf(x_min)) | (torch.isinf(y_min)) | (torch.isinf(z_min))
    mask[invalid_mask] = 0
    return 


def box_xyzxyz_to_cxcyczwhd(boxes: Tensor) -> Tensor:
    """
    Converts bounding boxes from (x1, y1, z1, x2, y2, z2) format to (cx, cy, cz, w, h, d) format.
    (x1, y1, z1) refer to top left of bounding box
    (x2, y2, z2) refer to bottom right of bounding box
    Args:
        boxes (Tensor[N, 6]): boxes in (x1, y1, z1, x2, y2, z2) format which will be converted.

    Returns:
        boxes (Tensor(N, 6)): boxes in (cx, cy, cz w, h, d) format.
    """
    x1, y1, z1, x2, y2, z2 = boxes.unbind(-1)
    cx = (x1 + x2) / 2
    cy = (y1 + y2) / 2
    cz = (z1 + z2) / 2
    w = x2 - x1
    h = y2 - y1
    d = z2 - z1

    boxes = torch.stack((cx, cy, cz, w, h, d), dim=-1)

    return boxes


# implementation from https://github.com/kuangliu/torchcv/blob/master/torchcv/utils/box.py
# with slight modifications
def _box_inter_union(boxes1: Tensor, boxes2: Tensor) -> Tuple[Tensor, Tensor]:
    vol1 = box_volume(boxes1)
    vol2 = box_volume(boxes2)

    lt = torch.max(boxes1[:, None, :3], boxes2[:, :3])  # [N,M,3]
    rb = torch.min(boxes1[:, None, 3:], boxes2[:, 3:])  # [N,M,3]

    dims = _upcast(rb - lt).clamp(min=0)  # [N,M,3]
    inter = dims[:, :, 0] * dims[:, :, 1] * dims[:, :, 2]  # [N,M]

    union = vol1[:, None] + vol2 - inter

    return inter, union


def box_volume(boxes: Tensor) -> Tensor:
    boxes = _upcast(boxes)
    return (boxes[:, 3] - boxes[:, 0]) * (boxes[:, 4] - boxes[:, 1]) * (boxes[:, 5] - boxes[:, 2])


def _upcast(t: Tensor) -> Tensor:
    # Protects from numerical overflows in multiplications
    # by upcasting to the equivalent higher type
    if t.is_floating_point():
        return t if t.dtype in (torch.float32, torch.float64) else t.float()
    else:
        return t if t.dtype in (torch.int32, torch.int64) else t.int()
    

def bitmask_to_boxes(masks: torch.Tensor) -> torch.Tensor:
    assert masks.dim() == 4, f"Expected (N, D, H, W), got {masks.shape}"

    N, D, H, W = masks.shape
    device = masks.device

    if N == 0:
        return masks.new_zeros((0, 6), dtype=torch.float32)

    # Treat non-zero as foreground
    if masks.dtype is torch.bool:
        masks_bool = masks
    else:
        masks_bool = masks != 0

    boxes = torch.zeros((N, 6), dtype=torch.float32, device=device)

    # occupancy along each principal axis
    # shapes: (N, W), (N, H), (N, D)
    x_any = masks_bool.any(dim=(1, 2))  # collapse D,H -> occupancy along X
    y_any = masks_bool.any(dim=(1, 3))  # collapse D,W -> occupancy along Y
    z_any = masks_bool.any(dim=(2, 3))  # collapse H,W -> occupancy along Z

    for idx in range(N):
        xs = torch.where(x_any[idx])[0]
        ys = torch.where(y_any[idx])[0]
        zs = torch.where(z_any[idx])[0]

        if xs.numel() and ys.numel() and zs.numel():
            # +1 on the max corner to keep the [min, max+1) convention
            boxes[idx] = torch.tensor(
                [xs[0], ys[0], zs[0],
                 xs[-1] + 1, ys[-1] + 1, zs[-1] + 1],
                dtype=torch.float32,
                device=device,
            )
        # else: leave that row as zeros for empty mask

    return boxes